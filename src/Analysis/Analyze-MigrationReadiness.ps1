<#
.SYNOPSIS
Analyzes Windows Server audit data to recommend optimal migration destinations and generate readiness scores.

.DESCRIPTION
Processes audit JSON from T1-T3 collectors and generates structured migration recommendations including:
- Workload classification (web, database, file server, etc.)
- Migration readiness score (0-100)
- Identification of migration blockers
- Top 3 destination options (Azure VM, App Service, on-prem modern, etc.)
- Estimated total cost of ownership (TCO) per option
- Remediation plan (critical, important, nice-to-have)
- Timeline estimates (assessment, planning, remediation, migration, validation, decommission)

.PARAMETER AuditPath
Path to the audit JSON file generated by Invoke-ServerAudit.ps1

.PARAMETER OutputPath
Optional: Path to export decision JSON. If not specified, returns object only.

.PARAMETER CustomWeights
Optional: Hashtable of scoring weights @{ ServerHealth = 0.25; AppCompatibility = 0.25; ... }

.PARAMETER Regions
Optional: Array of Azure regions to analyze for TCO comparison (default: EastUS, WestEurope)

.EXAMPLE
$decision = Analyze-MigrationReadiness -AuditPath ".\audit_results\SERVER01_audit_2025-11-21.json"
$decision.migrationOptions | Select-Object rank, destination, estimatedTCO

.EXAMPLE
$decisions = Get-ChildItem ".\audit_results\*.json" | ForEach-Object {
    Analyze-MigrationReadiness -AuditPath $_.FullName -OutputPath ".\decisions\$($_.BaseName)-decision.json"
}

.NOTES
Phase: T4 (Migration Decisions Engine)
Status: Phase 1 (Core Engine)
Depends: Invoke-ServerAudit.ps1 (T1-T3 audit data)
Output: JSON with workload classification, readiness score, recommendations, TCO, remediation plan
#>

[CmdletBinding()]
param(
    [Parameter(Mandatory=$true)]
    [ValidateScript({Test-Path $_ -PathType Leaf})]
    [string]$AuditPath,
    
    [Parameter(Mandatory=$false)]
    [string]$OutputPath,
    
    [Parameter(Mandatory=$false)]
    [hashtable]$CustomWeights,
    
    [Parameter(Mandatory=$false)]
    [string[]]$Regions = @("EastUS", "WestEurope")
)

Set-StrictMode -Version 2.0
$ErrorActionPreference = 'Stop'

Write-Verbose "$(Get-Date) : Starting migration readiness analysis for $AuditPath"

# ========================================
# Section 1: Load & Validate Audit Data
# ========================================

try {
    $auditJson = Get-Content -Path $AuditPath -Raw | ConvertFrom-Json
    Write-Verbose "Loaded audit data for: $($auditJson.computerName)"
}
catch {
    throw "Failed to load audit JSON from $AuditPath : $($_.Exception.Message)"
}

# ========================================
# Section 2: Workload Classification
# ========================================

function Invoke-WorkloadClassification {
    <#
    .SYNOPSIS
    Analyzes installed applications and services to classify workload type.
    
    .DESCRIPTION
    Examines T1-T3 collector data to determine primary workload classification:
    - Web Server (IIS detected)
    - Database Server (SQL/MySQL/PostgreSQL detected)
    - File Server (large shares, minimal applications)
    - Application Server (COTS or custom business applications)
    - Domain Controller (Active Directory detected)
    - Hybrid Infrastructure (multiple roles)
    
    Returns classification with confidence score (0-1).
    #>
    param([object]$AuditData)
    
    $classification = @{
        primaryType = "Unknown"
        confidence = 0.0
        secondaryTypes = @()
        keyApplications = @()
        estimatedWorkloadSize = "Unknown"
    }
    
    # Phase 1: Detect workload indicators from T1-T3 data
    $hasIIS = $false
    $hasSQL = $false
    $hasExchange = $false
    $hasHyperV = $false
    $hasAD = $false
    $hasLargeShares = $false
    $shareCount = 0
    $appCount = 0
    $installedApps = @()
    
    # Phase 2: Extract workload indicators from audit data
    try {
        # IIS Detection
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-IISInfo") {
            $iisData = $auditJson.collectors."Get-IISInfo".data
            if ($iisData.installed -eq $true -and $iisData.sites.Count -gt 0) {
                $hasIIS = $true
                $classification.keyApplications += "IIS $($iisData.version)"
            }
        }
        
        # SQL Server Detection
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-SQLServerInfo") {
            $sqlData = $auditJson.collectors."Get-SQLServerInfo".data
            if ($sqlData.instances.Count -gt 0) {
                $hasSQL = $true
                foreach ($instance in $sqlData.instances) {
                    $classification.keyApplications += "SQL Server $($instance.version)"
                }
            }
        }
        
        # Exchange Detection
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-ExchangeInfo") {
            $exchData = $auditJson.collectors."Get-ExchangeInfo".data
            if ($exchData.installed -eq $true) {
                $hasExchange = $true
                $classification.keyApplications += "Exchange $($exchData.version)"
            }
        }
        
        # Hyper-V Detection
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-HyperVInfo") {
            $hvData = $auditJson.collectors."Get-HyperVInfo".data
            if ($hvData.installed -eq $true -and $hvData.vmCount -gt 0) {
                $hasHyperV = $true
                $classification.keyApplications += "Hyper-V ($($hvData.vmCount) VMs)"
            }
        }
        
        # Active Directory Detection
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-ADInfo") {
            $adData = $auditJson.collectors."Get-ADInfo".data
            if ($adData.isDomainController -eq $true) {
                $hasAD = $true
                $classification.keyApplications += "Active Directory"
            }
        }
        
        # File Share Detection
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-ShareInfo") {
            $shareData = $auditJson.collectors."Get-ShareInfo".data
            if ($shareData.Count -gt 0) {
                $shareCount = $shareData.Count
                $totalShareSize = ($shareData | Measure-Object -Property SizeGB -Sum).Sum
                if ($totalShareSize -gt 100) {  # >100 GB = significant shares
                    $hasLargeShares = $true
                }
            }
        }
        
        # Application Count
        if ($auditJson.collectors.PSObject.Properties.Name -contains "Get-InstalledApps") {
            $appsData = $auditJson.collectors."Get-InstalledApps".data
            $appCount = $appsData.Count
            $installedApps = $appsData.Name
        }
        
        # Workload Size Estimation
        if ($appCount -lt 10) {
            $classification.estimatedWorkloadSize = "Small"
        }
        elseif ($appCount -lt 30) {
            $classification.estimatedWorkloadSize = "Medium"
        }
        elseif ($appCount -lt 100) {
            $classification.estimatedWorkloadSize = "Large"
        }
        else {
            $classification.estimatedWorkloadSize = "Enterprise"
        }
    }
    catch {
        Write-Verbose "Error extracting workload indicators: $_"
    }
    
    # Phase 3: Determine primary workload type based on indicators
    $typeScores = @{
        WebServer = 0
        DatabaseServer = 0
        FileServer = 0
        ApplicationServer = 0
        DomainController = 0
        ExchangeServer = 0
        HyperVHost = 0
    }
    
    if ($hasIIS) { $typeScores.WebServer += 50; $typeScores.ApplicationServer += 10 }
    if ($hasSQL) { $typeScores.DatabaseServer += 50; $typeScores.ApplicationServer += 10 }
    if ($hasExchange) { $typeScores.ExchangeServer += 60 }
    if ($hasHyperV) { $typeScores.HyperVHost += 50 }
    if ($hasAD) { $typeScores.DomainController += 60 }
    if ($hasLargeShares -and $appCount -lt 10) { $typeScores.FileServer += 40 }
    
    # Determine primary type
    $primaryScore = $typeScores.Values | Measure-Object -Maximum
    if ($primaryScore.Maximum -gt 0) {
        $primaryType = $typeScores.GetEnumerator() | Where-Object { $_.Value -eq $primaryScore.Maximum } | Select-Object -First 1
        $classification.primaryType = $primaryType.Name
        $classification.confidence = [Math]::Min(1.0, $primaryScore.Maximum / 100)
    }
    elseif ($appCount -gt 0) {
        $classification.primaryType = "ApplicationServer"
        $classification.confidence = 0.5
    }
    else {
        $classification.primaryType = "Unknown"
        $classification.confidence = 0.0
    }
    
    # Phase 4: Identify secondary types
    foreach ($type in $typeScores.GetEnumerator()) {
        if ($type.Value -gt 0 -and $type.Name -ne $classification.primaryType) {
            $classification.secondaryTypes += $type.Name
        }
    }
    
    # Phase 5: Set key applications
    if ($classification.keyApplications.Count -eq 0) {
        $classification.keyApplications = @($installedApps | Select-Object -First 3)
    }
    
    Write-Verbose "Workload classification: $($classification.primaryType) (confidence: $($classification.confidence))"
    return $classification
}

# ========================================
# Section 3: Readiness Scoring
# ========================================

function Invoke-ReadinessScoring {
    <#
    .SYNOPSIS
    Calculates migration readiness score (0-100) based on multiple factors.
    
    .DESCRIPTION
    Weighted scoring across five dimensions:
    - Server Health (OS age, support status, hardware capacity) - 25%
    - Application Compatibility (EOL status, cloud-native readiness) - 25%
    - Data Readiness (PII detection, link health, hardcoded paths) - 25%
    - Network Readiness (firewall rules, DNS, WinRM) - 15%
    - Compliance (regulatory requirements, data residency) - 10%
    
    Returns overall score 0-100 and component breakdown.
    #>
    param(
        [object]$AuditData,
        [hashtable]$Weights
    )
    
    $scores = @{
        serverHealth = 0
        appCompatibility = 0
        dataReadiness = 0
        networkReadiness = 0
        compliance = 0
    }
    
    $blockers = @()
    
    # Phase 1: Server Health Scoring (OS version, hardware, support status)
    try {
        $serverData = $AuditData.collectors."Get-ServerInfo".data
        $osVersion = $serverData.osVersion
        
        # OS Version scoring (0-100)
        switch -Regex ($osVersion) {
            "2008 R2" {
                $scores.serverHealth = 10  # EOL, very risky
                $blockers += "Windows Server 2008 R2 is EOL (supported until Jan 13, 2026) - recommend Server 2019+ or cloud migration"
            }
            "2012 R2" {
                $scores.serverHealth = 40  # Extended support until Oct 2023
                $blockers += "Windows Server 2012 R2 approaching end of support - plan upgrade"
            }
            "2016" {
                $scores.serverHealth = 75  # Mainstream support until Jan 2022, Extended until Jan 2027
            }
            "2019" {
                $scores.serverHealth = 85  # Mainstream support until May 2024, Extended until May 2029
            }
            "2022" {
                $scores.serverHealth = 95  # Latest, supported until Oct 2031
            }
            default {
                $scores.serverHealth = 50  # Unknown version, be conservative
            }
        }
        
        # Adjust based on hardware specs
        $cpuCount = $serverData.processorCount
        $ramGB = $serverData.totalMemoryMB / 1024
        $uptime = $serverData.systemUptime
        
        # Hardware capability bonus (up to +20 points)
        if ($cpuCount -ge 4 -and $ramGB -ge 8) {
            $scores.serverHealth += 10
        }
        if ($cpuCount -ge 8 -and $ramGB -ge 16) {
            $scores.serverHealth += 10
        }
        
        # Uptime bonus (indicates stability)
        if ($uptime -gt 365) {
            $scores.serverHealth += 5
        }
        
        $scores.serverHealth = [Math]::Min(100, $scores.serverHealth)
    }
    catch {
        Write-Verbose "Error calculating server health score: $_"
        $scores.serverHealth = 50
    }
    
    # Phase 2: Application Compatibility Scoring
    try {
        $appsData = $AuditData.collectors."Get-InstalledApps".data
        if ($appsData.Count -gt 0) {
            # Check for EOL applications (simplified, based on name patterns)
            $eolPatterns = @("Windows Server 2003", "Windows XP", "SQL Server 2005", "SQL Server 2008", "Exchange 2007", "SharePoint 2007", "Office XP", "Office 2003")
            $eolApps = $appsData | Where-Object { 
                $appName = $_.Name
                $eolPatterns | Where-Object { $appName -like "*$_*" }
            }
            
            if ($eolApps.Count -gt 0) {
                $scores.appCompatibility = 30
                $blockers += "EOL applications detected: $($eolApps.Name -join ', ') - require replacement or retirement"
            }
            else {
                $scores.appCompatibility = 70  # Assume modern if no EOL detected
            }
            
            # Adjust for app count (more apps = higher risk)
            if ($appsData.Count -lt 10) {
                $scores.appCompatibility += 20
            }
            elseif ($appsData.Count -lt 30) {
                $scores.appCompatibility += 10
            }
        }
        else {
            $scores.appCompatibility = 85  # No apps = highly migratable
        }
        
        $scores.appCompatibility = [Math]::Min(100, $scores.appCompatibility)
    }
    catch {
        Write-Verbose "Error calculating app compatibility score: $_"
        $scores.appCompatibility = 60
    }
    
    # Phase 3: Data Readiness Scoring (PII, hardcoded paths, links)
    try {
        $dataScore = 70  # Start with baseline
        
        # PII Detection penalty
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Data-Discovery-PII") {
            $piiData = $AuditData.collectors."Data-Discovery-PII".data
            if ($piiData.piiDetected -eq $true) {
                $dataScore -= 20  # Significant compliance implications
                $blockers += "PII detected on file shares ($($piiData.patterns.Count) pattern types) - requires data classification and encryption"
            }
        }
        
        # Hardcoded path detection (from T3)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Extract-DocumentLinks") {
            $linkData = $AuditData.collectors."Extract-DocumentLinks".data
            if ($linkData.Summary.LocalPaths -gt 0) {
                $dataScore -= ($linkData.Summary.LocalPaths * 0.5)  # Penalty per hardcoded path
                $blockers += "Hardcoded local paths found in $($linkData.Summary.LocalPaths) documents - require remediation before migration"
            }
        }
        
        $scores.dataReadiness = [Math]::Max(10, [Math]::Min(100, $dataScore))
    }
    catch {
        Write-Verbose "Error calculating data readiness score: $_"
        $scores.dataReadiness = 70
    }
    
    # Phase 4: Network Readiness Scoring
    try {
        $netScore = 75
        
        # Check for DNS/DHCP configuration
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-ServerInfo") {
            $serverData = $AuditData.collectors."Get-ServerInfo".data
            if ($serverData.networkAdapters.Count -gt 0) {
                $netScore += 15
                
                # DHCP enabled = less control = slightly lower score
                $dhcpCount = ($serverData.networkAdapters | Where-Object { $_.dhcpEnabled -eq $true }).Count
                if ($dhcpCount -gt 0) {
                    $netScore -= 5
                }
            }
        }
        
        $scores.networkReadiness = [Math]::Max(50, [Math]::Min(100, $netScore))
    }
    catch {
        Write-Verbose "Error calculating network readiness score: $_"
        $scores.networkReadiness = 75
    }
    
    # Phase 5: Compliance Scoring
    try {
        $compScore = 80
        
        # PII or UK Financial data detection
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Data-Discovery-PII") {
            $piiData = $AuditData.collectors."Data-Discovery-PII".data
            if ($piiData.piiDetected -eq $true) {
                $compScore -= 10  # Requires GDPR/CCPA compliance
            }
        }
        
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Data-Discovery-FinancialUK") {
            $finData = $AuditData.collectors."Data-Discovery-FinancialUK".data
            if ($finData.financialDataDetected -eq $true) {
                $compScore -= 15  # Requires FCA compliance, regional hosting
            }
        }
        
        $scores.compliance = [Math]::Max(50, [Math]::Min(100, $compScore))
    }
    catch {
        Write-Verbose "Error calculating compliance score: $_"
        $scores.compliance = 80
    }
    
    # Phase 6: Calculate overall weighted score
    $overallScore = (
        ($scores.serverHealth * $Weights.ServerHealth) +
        ($scores.appCompatibility * $Weights.AppCompatibility) +
        ($scores.dataReadiness * $Weights.DataReadiness) +
        ($scores.networkReadiness * $Weights.NetworkReadiness) +
        ($scores.compliance * $Weights.Compliance)
    ) | ForEach-Object { [Math]::Round($_, 0) }
    
    Write-Verbose "Readiness score: $overallScore (Server:$($scores.serverHealth) App:$($scores.appCompatibility) Data:$($scores.dataReadiness) Net:$($scores.networkReadiness) Comp:$($scores.compliance))"
    
    return @{
        overall = $overallScore
        components = $scores
        blockers = $blockers
    }
}

# ========================================
# Section 4: Migration Blocker Detection
# ========================================

function Find-MigrationBlockers {
    <#
    .SYNOPSIS
    Identifies migration showstoppers and risks.
    
    .DESCRIPTION
    Detects:
    - Unsupported OS versions (Server 2003, 2008, early versions)
    - EOL applications (no vendor support)
    - Hardcoded paths in documents (from T3 data)
    - Expiring SSL certificates
    - Critical service dependencies
    - Compliance constraints
    #>
    param([object]$AuditData)
    
    $blockers = @()
    
    # Phase 1: OS Version Validation
    try {
        $serverData = $AuditData.collectors."Get-ServerInfo".data
        $osVersion = $serverData.osVersion
        
        if ($osVersion -match "2003|2008.*R2|XP|Vista") {
            $blockers += @{
                Issue = "Unsupported OS Version"
                Description = "Server is running $osVersion which is no longer supported by Microsoft"
                Severity = "CRITICAL"
                Recommendation = "Upgrade to Server 2012 R2+ or migrate to cloud"
            }
        }
        elseif ($osVersion -match "2008[^R]|2008$") {
            $blockers += @{
                Issue = "Legacy OS Version"
                Description = "Server is running Windows Server 2008 (non-R2), support ending soon"
                Severity = "HIGH"
                Recommendation = "Plan upgrade to Server 2016+ within 12 months"
            }
        }
    }
    catch {
        Write-Verbose "Error checking OS version: $_"
    }
    
    # Phase 2: Application EOL Detection
    try {
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-InstalledApps") {
            $appsData = $AuditData.collectors."Get-InstalledApps".data
            
            # Define EOL application patterns
            $eolApps = @{
                "SQL Server 2005" = "2016-04-12"
                "SQL Server 2008" = "2019-07-09"
                "SQL Server 2012" = "2022-07-12"
                "Exchange 2007" = "2017-04-11"
                "Exchange 2010" = "2020-01-14"
                "SharePoint 2007" = "2017-10-10"
                "SharePoint 2010" = "2020-04-13"
            }
            
            foreach ($app in $appsData) {
                $eolMatch = $eolApps.GetEnumerator() | Where-Object { $app.Name -like "*$($_.Key)*" }
                if ($eolMatch) {
                    $blockers += @{
                        Issue = "EOL Application Detected"
                        Description = "$($app.Name) version $($app.Version) is no longer supported (EOL: $($eolMatch.Value))"
                        Severity = "HIGH"
                        Recommendation = "Plan application upgrade, replacement, or retirement"
                    }
                }
            }
        }
    }
    catch {
        Write-Verbose "Error checking for EOL applications: $_"
    }
    
    # Phase 3: Hardcoded Path Detection (from T3)
    try {
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Extract-DocumentLinks") {
            $linkData = $AuditData.collectors."Extract-DocumentLinks".data
            if ($linkData.Summary.LocalPaths -gt 0) {
                $blockers += @{
                    Issue = "Hardcoded Local Paths in Documents"
                    Description = "$($linkData.Summary.LocalPaths) documents contain hardcoded C:\ or D:\ paths that will break after migration"
                    Severity = "HIGH"
                    Recommendation = "Use Invoke-DocumentLinkAudit remediation to convert to UNC paths before migration"
                }
            }
        }
    }
    catch {
        Write-Verbose "Error checking for hardcoded paths: $_"
    }
    
    # Phase 4: Certificate Expiry Check
    try {
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-CertificateInfo") {
            $certData = $AuditData.collectors."Get-CertificateInfo".data
            if ($certData -is [array]) {
                foreach ($cert in $certData) {
                    $daysToExpiry = (New-TimeSpan -End $cert.NotAfter -Start (Get-Date)).Days
                    if ($daysToExpiry -lt 0) {
                        $blockers += @{
                            Issue = "Expired SSL Certificate"
                            Description = "Certificate $($cert.Subject) expired on $($cert.NotAfter)"
                            Severity = "CRITICAL"
                            Recommendation = "Renew immediately - service is at risk"
                        }
                    }
                    elseif ($daysToExpiry -lt 30) {
                        $blockers += @{
                            Issue = "SSL Certificate Expiring Soon"
                            Description = "Certificate $($cert.Subject) expires in $daysToExpiry days ($($cert.NotAfter))"
                            Severity = "HIGH"
                            Recommendation = "Renew certificate before migration cutover to avoid service interruption"
                        }
                    }
                }
            }
        }
    }
    catch {
        Write-Verbose "Error checking certificate expiry: $_"
    }
    
    # Phase 5: Service Dependency Detection
    try {
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-Services") {
            $servicesData = $AuditData.collectors."Get-Services".data
            
            # Check for critical services with external dependencies
            $criticalServices = @("MSSQLSERVER", "W3SVC", "MSExchangeIS", "Hyper-V")
            foreach ($critService in $criticalServices) {
                $service = $servicesData | Where-Object { $_.Name -eq $critService }
                if ($service) {
                    # Service exists = likely critical dependency
                    if ($service.Status -eq "Running") {
                        # We'll note this but not as a blocker - dependencies are handled in planning
                    }
                }
            }
        }
    }
    catch {
        Write-Verbose "Error checking service dependencies: $_"
    }
    
    # Phase 6: Compliance Constraints
    try {
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Data-Discovery-PII") {
            $piiData = $AuditData.collectors."Data-Discovery-PII".data
            if ($piiData.piiDetected -eq $true) {
                $blockers += @{
                    Issue = "PII Compliance Requirements"
                    Description = "Server contains PII data (SSN, credit cards, email, etc.) - requires regional hosting and data residency planning"
                    Severity = "MEDIUM"
                    Recommendation = "Ensure GDPR/CCPA compliance in destination region; consider EU or US regional constraints"
                }
            }
        }
        
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Data-Discovery-FinancialUK") {
            $finData = $AuditData.collectors."Data-Discovery-FinancialUK".data
            if ($finData.financialDataDetected -eq $true) {
                $blockers += @{
                    Issue = "UK Financial Data Constraints"
                    Description = "Server contains UK financial data (IBAN, sort codes, NI numbers) - requires FCA compliance and UK hosting"
                    Severity = "HIGH"
                    Recommendation = "Must migrate to UK region (UK South or similar) to maintain FCA compliance; data residency locked"
                }
            }
        }
    }
    catch {
        Write-Verbose "Error checking compliance constraints: $_"
    }
    
    return $blockers
}

# ========================================
# Section 5: Destination Recommendation
# ========================================

function Get-MigrationDestinations {
    <#
    .SYNOPSIS
    Generates top 3 migration destination recommendations.
    
    .DESCRIPTION
    Based on workload classification and readiness analysis, recommends:
    1. Primary destination (best fit for workload type and TCO)
    2. Alternative option (if primary has constraints)
    3. Fallback option (conservative choice)
    
    Each option includes platform, rationale, complexity, risk factors.
    #>
    param(
        [object]$AuditData,
        [string]$WorkloadType,
        [string[]]$Regions
    )
    
    $destinations = @()
    $region = $Regions[0]  # Primary region
    
    # Destination recommendation logic based on workload type
    switch ($WorkloadType) {
        "WebServer" {
            # Option 1: Azure App Service (PaaS, most modern)
            $destinations += @{
                rank = 1
                destination = "Azure App Service"
                platform = "Azure"
                category = "PaaS"
                rationale = "Web-only workload ideal for App Service; eliminates OS management, native auto-scaling, built-in CI/CD"
                complexity = "HIGH"
                downtime = "Zero (blue-green deployment)"
                riskFactors = @("Requires application refactoring", "Dependency on framework compatibility")
            }
            
            # Option 2: Azure VM (IaaS, safer)
            $destinations += @{
                rank = 2
                destination = "Azure VM (Standard_B2s - B4ms)"
                platform = "Azure"
                category = "IaaS"
                rationale = "Lift-and-shift migration, minimal app changes, retains OS control"
                complexity = "MEDIUM"
                downtime = "2-4 hours (planned cutover)"
                riskFactors = @("Ongoing OS patching required", "Higher long-term TCO")
            }
            
            # Option 3: On-Prem Modern (conservative)
            $destinations += @{
                rank = 3
                destination = "On-Premises Modern (Server 2022 refresh)"
                platform = "OnPrem"
                category = "IaaS"
                rationale = "Avoid cloud, extend support lifecycle, maintain current deployment patterns"
                complexity = "LOW"
                downtime = "1-2 hours"
                riskFactors = @("Hardware capex required", "Limited scalability")
            }
        }
        
        "DatabaseServer" {
            # Option 1: Azure SQL Database (managed)
            $destinations += @{
                rank = 1
                destination = "Azure SQL Database"
                platform = "Azure"
                category = "PaaS"
                rationale = "Fully managed SQL, automatic backups, built-in high availability, Azure security"
                complexity = "HIGH"
                downtime = "2-4 hours (migration window)"
                riskFactors = @("Schema/query compatibility", "T-SQL dialect differences")
            }
            
            # Option 2: Azure VM with SQL Server (IaaS)
            $destinations += @{
                rank = 2
                destination = "Azure VM (SQL Server 2019/2022)"
                platform = "Azure"
                category = "IaaS"
                rationale = "Full SQL Server feature parity, familiar management, Azure networking"
                complexity = "MEDIUM"
                downtime = "1-2 hours"
                riskFactors = @("OS and SQL patching required", "License cost implications")
            }
            
            # Option 3: On-Prem SQL Server (conservative)
            $destinations += @{
                rank = 3
                destination = "On-Premises SQL Server 2022"
                platform = "OnPrem"
                category = "IaaS"
                rationale = "Zero cloud adoption, maximum compatibility, familiar deployment"
                complexity = "LOW"
                downtime = "<1 hour"
                riskFactors = @("Hardware capex", "Support costs increase post-2024")
            }
        }
        
        "FileServer" {
            # Option 1: Azure Files (managed shares)
            $destinations += @{
                rank = 1
                destination = "Azure Files (SMB shares) + Blob Storage"
                platform = "Azure"
                category = "PaaS"
                rationale = "Fully managed file sharing, native SMB protocol, built-in backup and DR"
                complexity = "MEDIUM"
                downtime = "2-4 hours (share cutover)"
                riskFactors = @("Path mapping updates", "Quota management changes")
            }
            
            # Option 2: Azure VM with Storage Spaces
            $destinations += @{
                rank = 2
                destination = "Azure VM (File Server role) + Premium Storage"
                platform = "Azure"
                category = "IaaS"
                rationale = "VM-based shares, familiar admin model, fine-grained NTFS permissions"
                complexity = "MEDIUM"
                downtime = "2-4 hours"
                riskFactors = @("Ongoing OS patching", "Storage management required")
            }
            
            # Option 3: On-Prem NAS or VM
            $destinations += @{
                rank = 3
                destination = "On-Premises NAS/File Server"
                platform = "OnPrem"
                category = "IaaS"
                rationale = "Remain on-premises, avoid cloud complexity, maximum compatibility"
                complexity = "LOW"
                downtime = "1-2 hours"
                riskFactors = @("Hardware capex", "No cloud-native benefits")
            }
        }
        
        "DomainController" {
            # Option 1: Hybrid Azure AD (Azure AD DS)
            $destinations += @{
                rank = 1
                destination = "Azure AD Domain Services (Managed Domain)"
                platform = "Azure"
                category = "PaaS"
                rationale = "Managed AD in cloud, hybrid identity, Azure AD integration"
                complexity = "HIGH"
                downtime = "Staged cutover (weeks)"
                riskFactors = @("Hybrid setup complexity", "DNS reconfiguration", "Trust relationships")
            }
            
            # Option 2: Azure VM as Domain Controller
            $destinations += @{
                rank = 2
                destination = "Azure VM (Domain Controller role)"
                platform = "Azure"
                category = "IaaS"
                rationale = "Traditional AD in cloud, full feature parity, familiar deployment"
                complexity = "MEDIUM"
                downtime = "Managed cutover"
                riskFactors = @("Replication setup", "Site topology changes")
            }
            
            # Option 3: On-Prem DC (stay current)
            $destinations += @{
                rank = 3
                destination = "On-Premises Domain Controller (Server 2022)"
                platform = "OnPrem"
                category = "IaaS"
                rationale = "Remain on-premises, extend DC lifecycle, avoid cloud complexity"
                complexity = "LOW"
                downtime = "Minimal"
                riskFactors = @("Limited cloud integration", "No hybrid benefits")
            }
        }
        
        default {  # ApplicationServer or Hybrid
            # Option 1: Azure VM (safest)
            $destinations += @{
                rank = 1
                destination = "Azure VM (Standard_D2s_v3 - D4s_v3)"
                platform = "Azure"
                category = "IaaS"
                rationale = "Lift-and-shift suitable for mixed workloads, retains OS control, scales easily"
                complexity = "MEDIUM"
                downtime = "2-4 hours"
                riskFactors = @("Ongoing OS patching", "Networking setup required")
            }
            
            # Option 2: Azure Container Instance (if containerizable)
            $destinations += @{
                rank = 2
                destination = "Azure Container Instances / App Service"
                platform = "Azure"
                category = "PaaS"
                rationale = "If application containerizable, modern deployment, cost-effective"
                complexity = "HIGH"
                downtime = "Zero-downtime"
                riskFactors = @("Application containerization effort", "Dependency on frameworks")
            }
            
            # Option 3: On-Prem Modern Server
            $destinations += @{
                rank = 3
                destination = "On-Premises (Server 2022 refresh)"
                platform = "OnPrem"
                category = "IaaS"
                rationale = "Conservative approach, no cloud transformation, maximum compatibility"
                complexity = "LOW"
                downtime = "1-2 hours"
                riskFactors = @("Hardware capex", "Limited scalability")
            }
        }
    }
    
    return $destinations
}

# ========================================
# Section 6: TCO Calculation
# ========================================

function Invoke-CostEstimation {
    <#
    .SYNOPSIS
    Calculates total cost of ownership for each migration destination.
    
    .DESCRIPTION
    Estimates:
    - Monthly compute costs (VM size, App Service tier, etc.)
    - Monthly storage costs (data retention, backup)
    - Monthly networking costs (data transfer, bandwidth)
    - Licensing costs (Windows, SQL, 3rd-party apps)
    - Labor costs (remediation, migration, validation) based on complexity
    - Risk premium/discount based on complexity
    
    Returns first-year TCO for each destination.
    #>
    param(
        [object]$AuditData,
        [object]$Destination,
        [string]$Region,
        [double]$LaborRatePerHour = 125  # Default: $125/hour
    )
    
    # Azure pricing baseline (as of Nov 2025, approximate)
    # These are rough estimates for East US region; adjust for other regions
    $azurePricing = @{
        "Standard_B2s" = @{ compute = 30; storage = 32 }  # 2 vCPU, 4GB RAM
        "Standard_B4ms" = @{ compute = 120; storage = 128 }  # 4 vCPU, 16GB RAM
        "Standard_D2s_v3" = @{ compute = 96; storage = 32 }  # 2 vCPU, 8GB RAM
        "Standard_D4s_v3" = @{ compute = 192; storage = 64 }  # 4 vCPU, 16GB RAM
        "Azure App Service" = @{ compute = 65 }  # P1v2 tier
        "Azure SQL Database" = @{ compute = 150 }  # DTU tier
        "Azure Files" = @{ storage = 0.60 }  # Per GB/month
    }
    
    $tco = @{
        computeMonthly = 0
        storageMonthly = 0
        networkMonthly = 0
        licensingMonthly = 0
        laborEstimateHours = 0
        laborEstimateCost = 0
        totalFirstYearCost = 0
    }
    
    try {
        # Phase 1: Extract server specs for sizing
        $serverData = $AuditData.collectors."Get-ServerInfo".data
        $cpuCount = $serverData.processorCount
        $ramGB = $serverData.totalMemoryMB / 1024
        $diskGB = $serverData.diskInformationItems.SizeGB | Measure-Object -Sum | Select-Object -ExpandProperty Sum
        
        # Phase 2: Estimate compute costs based on destination
        switch -Regex ($Destination.destination) {
            "App Service|PaaS" {
                $tco.computeMonthly = $azurePricing."Azure App Service".compute
                $tco.laborEstimateHours = 80  # Refactoring effort
            }
            "SQL Database" {
                $tco.computeMonthly = $azurePricing."Azure SQL Database".compute
                $tco.laborEstimateHours = 120  # Migration + testing
            }
            "Azure Files" {
                $tco.storageMonthly = ($diskGB / 1024) * $azurePricing."Azure Files".storage
                $tco.laborEstimateHours = 16  # Share migration
            }
            "D2s_v3|D4s_v3|Standard_D" {
                # Extract VM size from destination
                if ($Destination.destination -match "D2s") {
                    $tco.computeMonthly = $azurePricing."Standard_D2s_v3".compute
                }
                else {
                    $tco.computeMonthly = $azurePricing."Standard_D4s_v3".compute
                }
                $tco.laborEstimateHours = 40  # Standard VM migration
            }
            "B2s|B4ms|Standard_B" {
                if ($Destination.destination -match "B2s") {
                    $tco.computeMonthly = $azurePricing."Standard_B2s".compute
                }
                else {
                    $tco.computeMonthly = $azurePricing."Standard_B4ms".compute
                }
                $tco.laborEstimateHours = 32  # Smaller workload
            }
            "On-Premises" {
                # On-prem: hardware capex + maintenance
                $tco.computeMonthly = 0  # Assume hardware already owned
                $tco.laborEstimateHours = 20  # Migration + setup
                # Add annual hardware maintenance (10% of initial capex)
                $estimatedHardwareCost = 8000 + ($cpuCount * 500) + ($ramGB * 50)
                $tco.networkMonthly += ($estimatedHardwareCost * 0.10 / 12)
            }
        }
        
        # Phase 3: Storage costs (if not included in compute)
        if ($tco.storageMonthly -eq 0 -and $diskGB -gt 0) {
            # Managed disk sizing: 30 GB base + data
            if ($diskGB -lt 64) {
                $tco.storageMonthly = 5  # Small disk
            }
            elseif ($diskGB -lt 256) {
                $tco.storageMonthly = 20  # Medium disk
            }
            else {
                $tco.storageMonthly = 50  # Large disk
            }
        }
        
        # Phase 4: Licensing costs
        switch -Regex ($Destination.destination) {
            "Azure.*SQL|SQL Server" {
                # SQL Server licensing (CAL model or per-core)
                $tco.licensingMonthly = 50 * $cpuCount  # Rough estimate
            }
            "On-Premises" {
                # On-prem: Windows Server license (if not covered by SA)
                $tco.licensingMonthly = 25  # Estimated
            }
        }
        
        # Phase 5: Network costs (egress/data transfer)
        if ($Destination.platform -eq "Azure") {
            $tco.networkMonthly = 10  # Minimal internal Azure networking
        }
        
        # Phase 6: Labor cost calculation
        $complexity = switch ($Destination.complexity) {
            "LOW" { 1.0 }
            "MEDIUM" { 1.3 }
            "HIGH" { 1.6 }
            default { 1.0 }
        }
        
        $tco.laborEstimateHours = [int]($tco.laborEstimateHours * $complexity)
        $tco.laborEstimateCost = $tco.laborEstimateHours * $LaborRatePerHour
        
        # Phase 7: Calculate first-year total
        $monthlyOperatingCost = $tco.computeMonthly + $tco.storageMonthly + $tco.networkMonthly + $tco.licensingMonthly
        $tco.totalFirstYearCost = [int](($monthlyOperatingCost * 12) + $tco.laborEstimateCost)
        
        Write-Verbose "TCO for $($Destination.destination): Monthly=$([int]$monthlyOperatingCost) / Year=$($tco.totalFirstYearCost)"
    }
    catch {
        Write-Verbose "Error calculating TCO: $_"
        $tco.totalFirstYearCost = 5000  # Conservative default
    }
    
    return $tco
}

# ========================================
# Section 7: Remediation Planning
# ========================================

function Build-RemediationPlan {
    <#
    .SYNOPSIS
    Creates prioritized remediation plan from identified issues.
    
    .DESCRIPTION
    Categorizes remediations as:
    - Critical (must fix before migration cutover)
    - Important (should fix during cutover window)
    - Nice-to-have (can fix post-cutover)
    
    Each includes issue description, recommendation, effort estimate, priority.
    #>
    param([object]$AuditData)
    
    $plan = @{
        critical = @()
        important = @()
        nice_to_have = @()
    }
    
    try {
        # Phase 1: Certificate/SSL remediation (CRITICAL)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-CertificateInfo") {
            $certs = $AuditData.collectors."Get-CertificateInfo".data
            $expiredCerts = $certs | Where-Object { [datetime]$_.NotAfter -lt (Get-Date).AddMonths(3) }
            
            if ($expiredCerts.Count -gt 0) {
                $plan.critical += @{
                    issue = "Expiring SSL/TLS Certificates"
                    count = $expiredCerts.Count
                    description = "Certificates expiring within 3 months"
                    recommendation = "Renew certificates before migration"
                    effortHours = 4 * $expiredCerts.Count
                    timeline = "Immediate"
                    risk = "Application downtime if cert expires during migration"
                }
            }
        }
        
        # Phase 2: Service dependency remediation (CRITICAL if broken)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-ServiceInfo") {
            $services = $AuditData.collectors."Get-ServiceInfo".data
            $stoppedServices = $services | Where-Object { $_.status -eq "Stopped" -and $_.startType -eq "Auto" }
            
            if ($stoppedServices.Count -gt 0) {
                $plan.critical += @{
                    issue = "Critical Services Not Running"
                    count = $stoppedServices.Count
                    description = "Services set to auto-start but currently stopped"
                    recommendation = "Investigate and restart services; fix startup issues"
                    effortHours = 2 * $stoppedServices.Count
                    timeline = "Before migration"
                    risk = "Application unavailability"
                }
            }
        }
        
        # Phase 3: Local path/shared drive remediation (IMPORTANT)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-ShareInfo") {
            $shares = $AuditData.collectors."Get-ShareInfo".data
            if ($shares.Count -gt 0) {
                $totalShareSize = ($shares | Measure-Object -Property SizeGB -Sum).Sum
                $plan.important += @{
                    issue = "Share Migration Planning"
                    shareCount = $shares.Count
                    totalSizeGB = $totalShareSize
                    description = "File shares need migration to cloud or Azure Files"
                    recommendation = "Plan share consolidation; identify stale content for archival"
                    effortHours = 8 + ($totalShareSize / 100)  # 0.08 hours per GB
                    timeline = "During migration window"
                    risk = "Data loss if shares not properly migrated"
                }
            }
        }
        
        # Phase 4: Event log/audit remediation (IMPORTANT)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-EventLogInfo") {
            $eventLogs = $AuditData.collectors."Get-EventLogInfo".data
            $plan.important += @{
                issue = "Event Log Archival"
                logCount = $eventLogs.Count
                description = "Event logs need archival before migration"
                recommendation = "Archive logs for compliance; reduce log size"
                effortHours = 4
                timeline = "Before migration"
                risk = "Compliance violation if logs lost"
            }
        }
        
        # Phase 5: Registry/config remediation (NICE-TO-HAVE)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-RegistryInfo") {
            $regData = $AuditData.collectors."Get-RegistryInfo".data
            $plan.nice_to_have += @{
                issue = "Registry Cleanup"
                description = "Orphaned registry entries from uninstalled software"
                recommendation = "Clean up registry; document any custom entries"
                effortHours = 4
                timeline = "Post-migration"
                risk = "None - minor performance optimization"
            }
        }
        
        # Phase 6: Print queue remediation (NICE-TO-HAVE)
        if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-PrinterInfo") {
            $printers = $AuditData.collectors."Get-PrinterInfo".data
            if ($printers.Count -gt 0) {
                $plan.nice_to_have += @{
                    issue = "Printer Configuration"
                    printerCount = $printers.Count
                    description = "Printers and print queues need reconfiguration"
                    recommendation = "Document printer settings for reconfiguration post-migration"
                    effortHours = 2 * $printers.Count
                    timeline = "Post-migration"
                    risk = "None - users can reconfigure as needed"
                }
            }
        }
        
        Write-Verbose "Remediation plan created: $($plan.critical.Count) critical, $($plan.important.Count) important, $($plan.nice_to_have.Count) nice-to-have"
    }
    catch {
        Write-Verbose "Error building remediation plan: $_"
    }
    
    return $plan
}

# ========================================
# Section 7B: Detailed Remediation Planning
# ========================================

function New-RemediationPlan {
    <#
    .SYNOPSIS
    Generates a prioritized remediation plan for compliance gaps.
    
    .DESCRIPTION
    Identifies gaps between current state and target destination, then creates
    a prioritized list of remediation tasks with effort estimates.
    
    Returns array of remediation items sorted by priority and effort.
    #>
    param(
        [object]$AuditData,
        [object]$Destination,
        [string]$Priority = "High,Medium,Low"  # Prioritize High-effort remediation
    )
    
    $remediationPlan = @()
    
    try {
        # Phase 1: Security baseline gaps
        $securityGaps = @()
        
        if ($Destination.destination -match "Azure|App Service|SQL") {
            # Check for Windows Firewall status
            if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-FirewallStatus") {
                $firewall = $AuditData.collectors."Get-FirewallStatus".data
                if ($firewall.profiles.firewallPolicy -ne "On") {
                    $securityGaps += @{
                        category = "Security"
                        item = "Windows Defender Firewall"
                        current = $firewall.profiles.firewallPolicy
                        required = "Enabled on all profiles"
                        effort = "LOW"
                        priority = 1
                    }
                }
            }
            
            # Check Windows Update status
            if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-WindowsUpdate") {
                $updates = $AuditData.collectors."Get-WindowsUpdate".data
                if ($updates.wuserver -notmatch "WSUS|Windows Update|Automatic") {
                    $securityGaps += @{
                        category = "Security"
                        item = "Windows Update Configuration"
                        current = $updates.wuserver
                        required = "Auto-update enabled"
                        effort = "LOW"
                        priority = 1
                    }
                }
            }
            
            # Check for TLS configuration
            if ($Destination.destination -match "SQL") {
                $securityGaps += @{
                    category = "Security"
                    item = "TLS 1.2+ Enforcement"
                    current = "TBD"
                    required = "TLS 1.2 minimum"
                    effort = "MEDIUM"
                    priority = 2
                }
            }
        }
        
        # Phase 2: Application configuration gaps
        $configGaps = @()
        
        if ($Destination.destination -match "App Service|PaaS") {
            # Check for application logging
            $configGaps += @{
                category = "Configuration"
                item = "Application Logging Setup"
                current = "Local event log"
                required = "Azure Application Insights"
                effort = "MEDIUM"
                priority = 2
            }
            
            # Check for error handling
            $configGaps += @{
                category = "Configuration"
                item = "Error Handling & Retry Logic"
                current = "May require refactoring"
                required = "Cloud-native patterns"
                effort = "HIGH"
                priority = 3
            }
        }
        
        # Phase 3: Database-specific remediation
        if ($Destination.destination -match "SQL Database|Data Warehouse") {
            if ($AuditData.collectors.PSObject.Properties.Name -contains "Get-ServiceInfo") {
                $services = $AuditData.collectors."Get-ServiceInfo".data
                $sqlServices = $services | Where-Object { $_.servicename -match "SQL|MSSQL" }
                
                if ($sqlServices) {
                    $configGaps += @{
                        category = "Database"
                        item = "SQL Server Feature Compatibility Review"
                        current = "On-Premises SQL"
                        required = "Azure SQL Database compatible"
                        effort = "HIGH"
                        priority = 3
                    }
                    
                    $configGaps += @{
                        category = "Database"
                        item = "Backup/Recovery Strategy"
                        current = "Local backups"
                        required = "Azure backup policies"
                        effort = "MEDIUM"
                        priority = 2
                    }
                }
            }
        }
        
        # Phase 4: Network/connectivity remediation
        if ($Destination.destination -match "Azure" -and $Destination.platform -eq "Azure") {
            $remediationPlan += @{
                category = "Network"
                item = "VPN/ExpressRoute Configuration"
                current = "N/A"
                required = "Secure hybrid connectivity"
                effort = "HIGH"
                priority = 3
                estimatedHours = 16
                dependencies = @("Security patches applied", "Network assessment complete")
            }
            
            $remediationPlan += @{
                category = "Network"
                item = "DNS/Naming Resolution"
                current = "On-Premises DNS"
                required = "Azure DNS or hybrid resolver"
                effort = "MEDIUM"
                priority = 2
                estimatedHours = 8
                dependencies = @()
            }
        }
        
        # Phase 5: Compliance & Audit remediation
        if ($Destination.platform -eq "Azure") {
            $remediationPlan += @{
                category = "Compliance"
                item = "Enable Azure Policy/Governance"
                current = "None"
                required = "Policy assignments per framework"
                effort = "MEDIUM"
                priority = 2
                estimatedHours = 12
                dependencies = @("Azure subscription configured")
            }
            
            $remediationPlan += @{
                category = "Compliance"
                item = "Configure Monitoring & Alerting"
                current = "Local monitoring"
                required = "Azure Monitor + alerts"
                effort = "MEDIUM"
                priority = 2
                estimatedHours = 10
                dependencies = @()
            }
        }
        
        # Combine all gaps
        $remediationPlan += $securityGaps + $configGaps
        
        # Phase 6: Prioritize and sort
        $priorityOrder = @{ "HIGH" = 10; "MEDIUM" = 5; "LOW" = 1 }
        $effortOrder = @{ "HIGH" = 20; "MEDIUM" = 10; "LOW" = 5 }
        
        $remediationPlan | ForEach-Object {
            $_.priority = $priorityOrder[$_.effort] + $effortOrder[$_.effort]
            if (-not $_.estimatedHours) {
                $_.estimatedHours = switch ($_.effort) {
                    "HIGH" { 24 }
                    "MEDIUM" { 12 }
                    "LOW" { 4 }
                    default { 8 }
                }
            }
            if (-not $_.dependencies) {
                $_.dependencies = @()
            }
        }
        
        # Sort by priority (descending) and effort (ascending within same priority)
        $remediationPlan = $remediationPlan | Sort-Object -Property @{Expression='priority';Descending=$true}, @{Expression='effort';Descending=$false}
        
        Write-Verbose "Generated remediation plan with $($remediationPlan.Count) items"
    }
    catch {
        Write-Verbose "Error generating remediation plan: $_"
    }
    
    return $remediationPlan
}

# ========================================
# Section 8: Timeline Estimation
# ========================================

function Estimate-MigrationTimeline {
    <#
    .SYNOPSIS
    Estimates project timeline from assessment through decommission.
    
    .DESCRIPTION
    Estimates phases:
    - Assessment: 1 week
    - Planning: 2 weeks
    - Remediation: 2-4 weeks (based on blockers)
    - Migration: 1 week
    - Validation: 2 weeks
    - Decommission: 4 weeks
    
    Adjusts based on workload complexity and blocker count.
    #>
    param(
        [object]$AuditData,
        [int]$BlockerCount,
        [string]$Complexity = "MEDIUM"
    )
    
    # Base timeline (in weeks)
    $baseTimeline = @{
        assessment = 1
        planning = 2
        remediation = 2
        migration = 1
        validation = 2
        decommission = 4
    }
    
    # Adjust remediation based on blocker count
    $remediationWeeks = $baseTimeline.remediation
    if ($BlockerCount -gt 5) {
        $remediationWeeks += ($BlockerCount - 5)  # Add 1 week per blocker over 5
    }
    
    # Adjust for complexity
    $complexityMultiplier = switch ($Complexity) {
        "LOW" { 0.8 }
        "MEDIUM" { 1.0 }
        "HIGH" { 1.5 }
        default { 1.0 }
    }
    
    # Apply multiplier to remediation and migration phases
    $remediationWeeks = [int]($remediationWeeks * $complexityMultiplier)
    $migrationWeeks = [int]($baseTimeline.migration * $complexityMultiplier)
    
    # Calculate totals
    $totalWeeks = $baseTimeline.assessment + $baseTimeline.planning + $remediationWeeks + $migrationWeeks + $baseTimeline.validation + $baseTimeline.decommission
    
    $timeline = @{
        assessmentPhase = @{
            duration = "$($baseTimeline.assessment) week"
            description = "Audit execution and initial analysis"
        }
        planningPhase = @{
            duration = "$($baseTimeline.planning) weeks"
            description = "Design, resource allocation, stakeholder prep"
        }
        remediationPhase = @{
            duration = "$remediationWeeks weeks"
            description = "Fix compliance gaps and blockers"
            adjustedFrom = $baseTimeline.remediation
            reason = switch {
                { $BlockerCount -gt 5 } { "High blocker count requires extended remediation" }
                { $Complexity -eq "HIGH" } { "High complexity requires extended remediation" }
                default { "Standard remediation timeline" }
            }
        }
        migrationPhase = @{
            duration = "$migrationWeeks weeks"
            description = "Workload transfer and cutover"
            adjustedFrom = $baseTimeline.migration
            reason = switch {
                { $Complexity -eq "HIGH" } { "High complexity requires extended migration" }
                default { "Standard migration timeline" }
            }
        }
        validationPhase = @{
            duration = "$($baseTimeline.validation) weeks"
            description = "Testing, verification, sign-off"
        }
        decommissionPhase = @{
            duration = "$($baseTimeline.decommission) weeks"
            description = "Data retention, archival, system shutdown"
        }
        summary = @{
            totalWeeks = $totalWeeks
            totalMonths = [math]::Round($totalWeeks / 4.33, 1)
            readinessDate = (Get-Date).AddWeeks($totalWeeks)
            criticality = switch {
                { $BlockerCount -gt 10 } { "CRITICAL - Extended timeline needed" }
                { $BlockerCount -gt 5 } { "HIGH - Significant remediation required" }
                { $Complexity -eq "HIGH" } { "HIGH - Complex workload" }
                { $Complexity -eq "MEDIUM" } { "MEDIUM - Standard timeline" }
                default { "LOW - On track for standard timeline" }
            }
        }
    }
    
    Write-Verbose "Timeline estimate: $totalWeeks weeks ($([math]::Round($totalWeeks/4.33, 1)) months)"
    
    return $timeline
}

# ========================================
# Main Execution
# ========================================

# Set default weights if not provided
$weights = $CustomWeights ?? @{
    ServerHealth = 0.25
    AppCompatibility = 0.25
    DataReadiness = 0.25
    NetworkReadiness = 0.15
    Compliance = 0.10
}

try {
    # Step 1: Classify workload
    $workload = Invoke-WorkloadClassification -AuditData $auditJson
    Write-Verbose "Workload: $($workload.primaryType)"
    
    # Step 2: Calculate readiness score
    $readiness = Invoke-ReadinessScoring -AuditData $auditJson -Weights $weights
    Write-Verbose "Readiness score: $($readiness.overall)/100"
    
    # Step 3: Find blockers
    $blockers = Find-MigrationBlockers -AuditData $auditJson
    Write-Verbose "Blockers found: $($blockers.Count)"
    
    # Step 4: Get destination recommendations
    $destinations = Get-MigrationDestinations -AuditData $auditJson `
        -WorkloadType $workload.primaryType -Regions $Regions
    Write-Verbose "Destinations generated: $($destinations.Count)"
    
    # Step 5: Calculate TCO for each destination
    foreach ($dest in $destinations) {
        $dest.estimatedTCO = Invoke-CostEstimation -AuditData $auditJson `
            -Destination $dest -Region ($Regions[0])
    }
    
    # Step 6: Build remediation plan
    $remediation = Build-RemediationPlan -AuditData $auditJson
    Write-Verbose "Remediation items: $($remediation.critical.Count + $remediation.important.Count)"
    
    # Step 7: Estimate timeline
    $timeline = Estimate-MigrationTimeline -AuditData $auditJson `
        -BlockerCount $blockers.Count -Complexity ($readiness.overall -lt 50 ? "HIGH" : "MEDIUM")
    
    # Build output object
    $decision = @{
        analyzeId = "analyze-$(Get-Date -Format 'yyyy-MM-dd')-$($auditJson.computerName)-$(Get-Random -Minimum 1000 -Maximum 9999)"
        timestamp = Get-Date -Format 'o'
        sourceServer = @{
            name = $auditJson.computerName
            os = $auditJson.operatingSystem
            powerShellVersion = $auditJson.powerShellVersion
        }
        workloadClassification = $workload
        readinessScore = $readiness
        migrationOptions = $destinations
        remediationPlan = $remediation
        timeline = $timeline
        blockers = $blockers
    }
    
    # Output
    Write-Verbose "Analysis complete. Preparing output."
    
    if ($OutputPath) {
        $decision | ConvertTo-Json -Depth 10 | Out-File -Path $OutputPath -Encoding UTF8
        Write-Host "Decision JSON saved to: $OutputPath"
    }
    
    return $decision
}
catch {
    Write-Error "Migration readiness analysis failed: $($_.Exception.Message)"
    throw
}
